\documentclass[a4paper,12pt]{report}
\usepackage{amsmath} %Use align

%Temporary stuff
\usepackage{draftcopy}
\usepackage[footnote,draft,silent,nomargin]{fixme}

\begin{document}

\title{Models in Pixel Based Phenology}
\author{Joel Granados \\ jogr@itu.dk}
\date{ \today }

\maketitle

\section*{Introduction}
Phenology is the study of plant and animal cycles and how they relate to the
seasons. Phenological measurements are of great importance to ecologists for a
number of reasons. We are interested not in the direct consequence of
phenological measurements, but in the way these measurements are done. More
specifically, we are studying a way to use digital imaging to automate plant
phenology data gathering.

\section{Description of the Data}
The data that we are handling in this experiment comes from a pan tilt zoom
camera. This camera takes pictures of a region of interest. This is done
throughout various seasons on a daily basis (Sometimes even more frequently).
Not all the pictures are usable, some of them just contain dirt and
uninteresting elements. Some, however, contain plants that interest the
biologist. These images of interest are ordered into season image series for
further analysis.

After having a season image series, we annotate images from one
season\footnote{We annotate images from one season in the hope that the
sample will be representative of all seasons; and can be used to detect
posterior seasons.}. Annotations consist in identifying pixels of interest.
We create two types of annotations: background annotations and foreground
annotations. Foreground is defined as whatever is of interest to
the biologist. This could be a flower, fern, a whole tree or a part of a tree.
Background is defined as the rest of the image. Notice that in our model the
foreground annotations are not necessarily the compliment of the background
ones.

After the annotations we get two pixel lists: a background pixel list and a
foreground pixel list. These two lists will be the base of our Naive Bayesian
Model. We will denominate the number of foreground pixels as $N_{FG}$ and
likewise denominate the number of background pixels as $N_{BG}$. Using probability
theory \cite{PATTERN:2007} we can calculate
the probability of a pixel being foreground or background\footnote{We will
denote the random variable expression foreground or background and $\Phi$}
by using the following equations:

\begin{equation}
P(\Phi= bg) = P(bg) = \frac{N_{BG}}{N_{BG}+N_{FG}}
\end{equation}

\begin{equation}
P(\Phi= fg) = P(fg) = \frac{N_{FG}}{N_{FG}+N_{BG}}
\end{equation}

For these probabilities to have any kind of meaning $N_{BG}$ and $N_{FG}$ need
to be calculated throughout a season. Note that if this is not possible we will
replace the values with something "sensible" like $P(fg)=.5$ and $P(bg)=.5$.
Further notice that we will use the notation from \cite{PATTERN:2007} where
lower case characters ($bg$) denote the value of a random variable ($\Phi$).
The random variable is denoted by an upper case character.

Depending on the color space each pixel contains several sub-dimensions. The RGB
color space -for example- has 3 sub-dimensions. There are lots of colors spaces and we have
lots of sub-dimensions to choose from. For the purpose of this document we assume
that each pixel has one or more sub-dimensions $D={D_1, D_2... D_n}$

\section{Discrete Model}
The first step is to discretize the values of each dimension. Technically the
values are already discrete. Think of an 8 bit value as 256 bins. But the model
can define a different number of bins. This value is a parameter for the
whole Discrete model.

We define the Naive Bayesian Model for any amount of sub-dimensions with the
following equation:

\begin{align}
P(\Phi \mid D)
    &= \frac{P(D \mid \Phi) P(\Phi)}
            {P(D)} \\
    &= \frac{P(D_1, D_2...D_n \mid \Phi) P(\Phi)}
            {P(D)} \\
    &= \frac{P(D_1 \mid \Phi)
             P(D_2 \mid \Phi) ...
             P(D_n \mid \Phi) P(\Phi)}
            {P(D)} \\
    &= \frac{(\prod_{i=1}^n{P(D_i \mid \Phi)}) P(\Phi)}
            {P(D)} \\
\end{align}

Therefore given a specific value $d={d_1,d_2...d_n}$ in the n-dimensional
pixel space, the probability for that specific pixel to be foreground is
given by:

\begin{equation}
P(fg \mid d) = \frac{(\prod_{i=1}^n{P(d_i \mid fg)}) P(fg)}{P(d)}
\end{equation}

We define $P(D_i \mid \Phi)$ as the probability of a pixel having the value $D_i$
given that it has been cataloged as $\Phi$. This conditional probability is
easily calculated by using the following equation:

\begin{equation}\label{eq:dimgivenphi}
P(D_i \mid \Phi) = \frac{N_{D_i\&\Phi}}{N_{\Phi}}
\end{equation}

With $N_{D_i\&\Phi}$ being the number of occurrences of the value $D_i$ within
$\Phi$ and $N_{\Phi}$ being the number of occurrences of a certain value of
$\Phi$ with respect all the $\Phi$ values.

Therefore given a specific sub-dimension value $d_i=k$, the probability of a
pixel having that value given that it has been cataloged as background is given
by the following expression:

\begin{equation}
P(k \mid bg) = \frac{N_{k\&fg}}{N_{fg}}
\end{equation}

With $N_{k\&fg}$ being the number of times a foreground pixel took the value of
$k$ and $N_{fg}$ is the number of foreground pixels.

In general we model each discrete value of each sub-dimension in
each pixel. This allows us to answer questions like: What is the probability of
a pixel being foreground given its value? Likewise for background.
These probabilities are important for our ultimate goal decide if a new pixel
is foreground or background\footnote{foreground being an element of interest
and background being other stuff}. By knowing which of these probabilities is
the greatest we are able to decide if a pixel is in the background group or the
foreground one. The following equation is true for pixels that are foreground
and false for the rest.

\begin{equation}\label{eq:comparison}
P(fg \mid d) >= P(bg \mid d)
\end{equation}

Notice that the denominator of both sides in equation \ref{eq:comparison}
cancels out. This means that there is no need to calculate $P(D)$ in the model.

\section{Continuous Model}
For the continuous model we skip the discretizing step and accept that the
color space sub-dimensions are continuous\footnote{sampled from
a continuous function}. Notice that the models are very similar, probably the
only thing that changes in the continuous model is the way we treat equation
\ref{eq:dimgivenphi}. The new equation is:

\begin{equation}\label{eq:dimgivenphigauss}
    P(D \mid \Phi) = \frac{1}{\sqrt{2 \pi \sigma_D^2}}
                       \exp{\frac{-(D - \mu_D)^2}{2 \sigma_D^2}}
\end{equation}

Where $\mu_D$ is the mean of dimension D conditioned to the value of $\Phi$. The
variable $\sigma_D^2$ is the variance of dimension D conditioned to the value of
$\Phi$. And D is the value of a pixel. Notice that we are using the Gaussian to
calculate $P(D \mid \Phi)$.

Therefore given the specific sub-dimension value $d_i=k$, the probability of a
pixel having that value given that it has been cataloged as foreground is given
by the following expression:

\begin{equation}\label{eq:dimgivenphigauss}
    P(k \mid fg) = \frac{1}{\sqrt{2 \pi \sigma_{d_i}^2}}
                   \exp{\frac{-(k - \mu_{d_i})^2}{2 \sigma_{d_i}^2}}
\end{equation}

\section{Additional Comments}
Though the change from discrete to continuous is a bit subtle there is a change
in the way the frequencies are calculated. For the discrete case we need to
calculate the frequency of each discrete value for each sub-dimension. On the
other hand, for the continuous case we need to calculate the mean and variance
of each sub-dimension.

The idea of having these two models is also to compare their behavior and see if
there is a considerable difference in using one or the other. The more common
\footnote{Common given my experience} way of dealing with these values is the
continuous model, but the discrete model is also valid.

\listoffixmes

\bibliographystyle{plain}
\bibliography{bayesianModelDefinition.bib}

\end{document}

