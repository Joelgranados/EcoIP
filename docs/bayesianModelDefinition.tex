\documentclass[a4paper,12pt]{report}

%Temporary stuff
\usepackage{draftcopy}
\usepackage[footnote,draft,silent,nomargin]{fixme}

\begin{document}

\title{Models in Pixel Based Phenology}
\author{Joel Granados \\ jogr@itu.dk}
\date{ \today }

\maketitle

\section*{Introduction}
Phenology is the study of plant and animal cycles and how they relate to the
seasons. Phenological measurements are of great importance to ecologists for a
number of reasons. We are interested not in the direct consequence of
phenological measurements, but in the way these measurements are done. More
specifically, we are studying a way to use digital imaging to automate plant
phenology data gathering.

\section{General Model: Naive Bayes Model}

\section{Description of the Data}
The data that we are handling in this experiment comes from a pan tilt zoom
camera. This camera takes pictures of a region of interest. This is done
throughout various seasons on a daily basis (Sometimes even more frequently).
Not all the pictures are usable, some of them just contain dirt and
uninteresting elements. Some, however, contain plants that interest the
biologist. It is these images are the initial data points. Before the data
analysis a coherent series of images (that describe a season) needs to be
created.

After having 1 or several season image series, we can begin the pixel color
analysis. Our next step is to annotate images from one season\footnote{We
annotate images from one season in the hope that the sample will be
representative of all seasons; and can be used to detect posterior seasons.}.
Annotations consist in identifying pixels of interest.
We create two types of annotations: background annotations and foreground
annotations. Foreground is defined as whatever is of interest to
the biologist. This could be a flower, fern, a whole tree or a part of a tree.
Background is defined as the rest of the image. Notice that in our model the
foreground annotations are not necessarily the compliment of the background
ones.

After the annotations we get two pixel lists: a background pixel list and a
foreground pixel list. These two lists will be the base of our Naive Bayesian
Models. We will denominate the number of foreground pixels as $N_{FG}$ and
likewise denominate the number of background pixels as $N_{BG}$. Using probability
theory \fxnote{cite Pattern Recognition and Machine Learning} we can calculate
the probability of a pixel \footnote{A pixel here is the random variable and we
will identify it by $\Phi$} being foreground or background by using the following
equations:

\begin{equation}
P(\Phi=_{BG}) = \frac{N_{BG}}{N_{BG}+N_{FG}} \\
\end{equation}

\begin{equation}
P(\Phi=_{FG}) = \frac{N_{FG}}{N_{FG}+N_{BG}}
\end{equation}

For these probabilities to have any kind of meaning $N_{BG}$ and $N_{FG}$ need
to be calculated throughout a season. Note that if this is not possible we will
replace the values with something "sensible" like $P(\Phi=_{FG})=.5$ and
$P(\Phi=_{BG})=.5$.

Depending on the color space each pixel contains several sub-dimensions. If we
were to choose the three values of the RGB colors space, the pixel would have 3
sub-dimensions. There are lots of colors spaces and we have lots of
sub-dimensions to choose from. For the purpose of this document we assume that
each pixel has one or more sub-dimensions. This needs to be handled by each
Naive Bayesian Model.

\section{Discrete Model}
The first step is to Discretize the values of each dimension. Technically the
values are already discrete. Like the 8 bit value of one of the dimensions of
the RGB color space. The values are placed within a Natural \footnote{I refer
here to the natural numbers} interval $0 \le X \le 255$. But the algorithm
might define a different number of discretezing bins. So, instead of 256 bins,
we can have 100. This value is a parameter for the whole Discrete model.

We define the Naive Bayesian Model by trying to find the probability of a pixel
being background (or foreground) given that a pixel is contained in bin $b$
($P(\Phi=_{FG} \mid \Phi=b)$). Taken directly from a Naive Bayesian Model, the
following equations help calculate the values we need:

\fxnote{We should describe the general model from the beginning with more than
one bin}

\begin{equation}
P(\Phi=_{FG} \mid \Phi=b) = \frac{P(\Phi=b \mid\Phi=_{FG}) \times P(\Phi=_{FG})}
                               {P(\Phi=b)}
\end{equation}

\begin{equation}
P(\Phi=_{BG} \mid \Phi=b) = \frac{P(\Phi=b \mid\Phi=_{BG}) \times P(\Phi=_{BG})}
                               {P(\Phi=b)}
\end{equation}

We define $P(\Phi=b \mid\Phi=_{BG})$ as the probability of a pixel being part of
bin $b$ given that it has been cataloged as background (or foreground). This
conditional probability is easily calculated by using the following equation:

\begin{equation}
P(\Phi=b \mid\Phi=_{BG}) = \frac{N_{b\&BG}}{N_{BG}}
\end{equation}

With $N_{b\&BG}$ being the number of background pixels that were in bin $b$. The
equation for foreground pixels is equally as easy to calculate:

\begin{equation}
P(\Phi=b \mid\Phi=_{FG}) = \frac{N_{b\&FG}}{N_{FG}}
\end{equation}

With $N_{b\&FG}$ being the number of foreground pixels that were in bin $b$.

\section{Continuous Model}

\listoffixmes
\end{document}

